{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T03:31:12.592028Z",
     "start_time": "2025-04-10T03:31:05.220352Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.datasets import Multi30k\n",
    "from config import config\n",
    "from model import Transformer\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "import data_utils\n",
    "importlib.reload(data_utils)\n",
    "from data_utils import (\n",
    "    build_vocab, token_transform, collate_fn,\n",
    "    create_src_mask, create_tgt_mask,\n",
    "    PAD_IDX, BOS_IDX, EOS_IDX\n",
    ")\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T03:31:14.437782Z",
     "start_time": "2025-04-10T03:31:12.603031Z"
    }
   },
   "cell_type": "code",
   "source": "vocab_transform = build_vocab()",
   "id": "a06891b32c58be1e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T03:31:14.521835Z",
     "start_time": "2025-04-10T03:31:14.519603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config[\"src_vocab_size\"] = len(vocab_transform[\"de\"])\n",
    "config[\"tgt_vocab_size\"] = len(vocab_transform[\"en\"])\n",
    "config[\"pad_idx\"] = PAD_IDX\n",
    "config[\"bos_idx\"] = BOS_IDX\n",
    "config[\"eos_idx\"] = EOS_IDX"
   ],
   "id": "123edfd18ae86444",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T03:31:14.681442Z",
     "start_time": "2025-04-10T03:31:14.528444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_iter = list(Multi30k(split='train'))\n",
    "train_loader = DataLoader(train_iter, batch_size=32, shuffle=True, collate_fn=lambda batch: collate_fn(batch, token_transform, vocab_transform))"
   ],
   "id": "af65743037a1a932",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T03:31:15.201944Z",
     "start_time": "2025-04-10T03:31:14.686462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Transformer(\n",
    "    src_vocab_size=config[\"src_vocab_size\"],\n",
    "    tgt_vocab_size=config[\"tgt_vocab_size\"],\n",
    "    model_dim=config[\"model_dim\"],\n",
    "    num_heads=config[\"num_heads\"],\n",
    "    ff_dim=config[\"ff_dim\"],\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    max_seq_length=config[\"max_seq_length\"],\n",
    "    dropout=config[\"dropout\"]\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ],
   "id": "7d0171bcc63bc2ef",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T04:24:01.086418Z",
     "start_time": "2025-04-10T03:31:15.219163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_epoch = 0\n",
    "num_epochs = config[\"num_epochs\"]\n",
    "checkpoint_path = \"checkpoints/checkpoint_latest.pt\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    best_loss = checkpoint[\"best_loss\"]\n",
    "    print(f\"üîÅ Resumed from epoch {start_epoch}, best_loss = {best_loss:.4f}\")\n",
    "else:\n",
    "    print(\"üöÄ Starting training from scratch.\")\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
    "\n",
    "    for src_batch, tgt_batch in progress_bar:\n",
    "        src_mask = create_src_mask(src_batch, config[\"pad_idx\"])\n",
    "        tgt_input = tgt_batch[:, :-1]\n",
    "        tgt_mask = create_tgt_mask(tgt_input, config[\"pad_idx\"])\n",
    "\n",
    "        logits = model(src_batch, tgt_input, src_mask, tgt_mask)\n",
    "        output = logits.reshape(-1, logits.size(-1))\n",
    "        target = tgt_batch[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / (progress_bar.n + 1)\n",
    "        progress_bar.set_postfix(loss=f\"{loss.item():.4f}\", avg=f\"{avg_loss:.4f}\")\n",
    "\n",
    "    tqdm.write(f\"Epoch {epoch+1} completed. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"best_loss\": best_loss\n",
    "    }\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    torch.save(checkpoint, \"checkpoints/checkpoint_latest.pt\")\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), \"checkpoints/transformer_best.pt\")\n",
    "        print(f\"‚úÖ Saved new best model with avg loss {avg_loss:.4f}\")"
   ],
   "id": "e839380b6a423f37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Resumed from epoch 6, best_loss = 1.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 907/907 [10:59<00:00,  1.37it/s, avg=1.2234, loss=1.3405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed. Average Loss: 1.2234\n",
      "‚úÖ Saved new best model with avg loss 1.2234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 907/907 [13:24<00:00,  1.13it/s, avg=1.0220, loss=0.8763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed. Average Loss: 1.0220\n",
      "‚úÖ Saved new best model with avg loss 1.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 907/907 [14:08<00:00,  1.07it/s, avg=0.8415, loss=0.8796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed. Average Loss: 0.8415\n",
      "‚úÖ Saved new best model with avg loss 0.8415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 907/907 [14:06<00:00,  1.07it/s, avg=0.6777, loss=0.6657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed. Average Loss: 0.6777\n",
      "‚úÖ Saved new best model with avg loss 0.6777\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
